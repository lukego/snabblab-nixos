---
title: "NFV test matrix"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(fig.width = 10, fig.height = 8)
```

```{r include=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(sfsmisc)
```
```{r}
d <- read.csv("bench.csv")
d$id <- as.factor(d$id)
d$pktsize <- as.factor(d$pktsize)

overall <- subset(as.data.frame(d), subset = benchmark == 'iperf' | benchmark == 'l2fwd')

iperf <- droplevels(subset(overall, subset = benchmark == 'iperf'))
l2fwd <- droplevels(subset(overall, subset = benchmark == 'l2fwd'))

# data frames with NA scores (failures) replaced with 0
overall0 <- data.frame(overall)
overall0$score[is.na(overall$score)] <- 0

iperf0 <- data.frame(iperf)
iperf0$score[is.na(iperf0$score)] <- 0

l2fwd0 <- data.frame(l2fwd)
l2fwd0$score[is.na(l2fwd0$score)] <- 0

ggplot_distribution <- function(dataframe) {
  return (ggplot(dataframe, aes(x=score, y=..count..)) +
    theme(legend.position="top") +
    geom_histogram(aes(fill=snabb), position = "dodge", bins=20, alpha=0.5) +
    geom_density(aes(color=snabb)))
}


```

Performance comparison between Snabb versions. Compares scores with various benchmarks, workloads, configurations, and software dependency versions. Results are mostly reported as [probability density graphs](https://en.wikipedia.org/wiki/Probability_density_function) to show the distribution of benchmark scores (measured in Gbps for iperf and Mpps for l2fwd).

The overall purpose of this report is to highlight the relative strengths and weaknesses between Snabb software versions. This is particularly intended for evaluating how experimental changes affect performance and reliability.

This report starts with a very broad summary and then drills down on iperf and l2fwd results separately.

## Significance test

This first graph is special: its purpose is to show whether there are "statistically significant" differences between the Snabb versions. It is plotted in an especially suitable way: a CDF (see [Reading CDF Graphs](http://docs.battlemesh.org/v8/ecdf.html)) with a 95% confidence band. (Explanation follows below.)

```{r fig.width=8, fig.height=5}
f <- function(data) {
  n <- length(data)
  D <- KSd(n)
  ec <- ecdf(data)
  x <- get("x", envir = environment(ec))
  y <- get("y", envir = environment(ec))
  tibble(x = x,
         ymax = pmin(y+D, 1),
         ymin = pmax(y-D, 0))
}

data <- tibble()
for (branch in levels(as.factor(d$snabb))) {
  new <- f(filter(d, snabb == branch)$score)
  new$snabb <- branch
  data <- rbind(data, new)
}
ggplot(data = data) +
  geom_ribbon(aes(x=x, ymin=1-ymin, ymax=1-ymax, color=snabb, fill=snabb),
              alpha=0.35) +
  scale_y_continuous(labels = scales::percent) +
  labs(y = "% of results above score on X-axis",
       x = "Benchmark score",
       title = "Branch-wise Snabb benchmark CDF",
       subtitle = "95% confidence band for Cumulative Distribution Function (CDF)")
```

Significant differences appear as gaps (blank space) between confidence bands. For each gap the band above seems to be significantly _faster_ than the band below. If bands criss-cross this suggests that one version is faster on some benchmarks and slower on others.

If two bands have no gaps (i.e. they overlap at every point on the X-axis) then no significant differences between those bands was found. In this case any apparent differences between branches in the other plots below should be taken with a grain of salt.

Notes: 

- Higher is better.
- The breadth of the confidence bands depends on the number of benchmarks. The more data you have, the narrower your bands, the easier it is to find small gaps. If you think there is a difference but the bands are too broad to be sure then consider re-running the benchmark with more iterations.
- The confidence bands are calculated using a method based on the [Kolmogorov-Smirnov (KS) test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test).

## Overall summary

```{r fig.width=8, fig.height=4}
ggplot_distribution(overall0) + ggtitle("Overall (MPPS or Gbps)")
```

### Split by benchmark

```{r fig.width=8, fig.height=6}
ggplot_distribution(overall0) + facet_wrap(~benchmark, scales = "free", ncol = 1, shrink = TRUE) + ggtitle("By benchmark (MPPS or Gbps)")
```

## iperf

```{r fig.width=8, fig.height=4}
ggplot_distribution(iperf0) + ggtitle("iperf overall (Gbps)")
```

### Configuration

```{r}
ggplot_distribution(iperf0) +facet_wrap(~config, ncol=2, scales = "free_y", shrink = TRUE) + ggtitle("iperf by configuration (Gbps)")
```

### Guest kernel

```{r}
ggplot_distribution(iperf0) + facet_wrap(~kernel, ncol=2, scales = "free_y", shrink = TRUE) + ggtitle("iperf by guest kernel (Gbps)")
```

### QEMU

```{r}
ggplot_distribution(iperf0) + facet_wrap(~qemu, ncol=2, scales = "free_y", shrink = TRUE) + ggtitle("iperf by qemu (Gbps)")
```

### Success and failure

Success rate:

```{r}
success = summarize(group_by(iperf, qemu, kernel, config, snabb), success = mean(!is.na(score)))
ggplot(success, aes(qemu, config, fill=success)) +
  geom_tile(aes(fill=success)) + scale_fill_gradient(limits=c(0,1), low="red", high="white") +
  geom_text(aes(label = scales::percent(success))) +
  facet_grid(snabb ~ kernel) +
  theme(axis.text.x = element_text(angle=45, vjust=1))
```

Sucesses:

```{r}
summary(subset(iperf, subset = !is.na(score), select = c(config, qemu, kernel)))
```

Failures:

```{r}
summary(subset(iperf, subset = is.na(score), select = c(config, qemu, kernel)))
```

## l2fwd

```{r fig.width=8, fig.height=4}
ggplot_distribution(l2fwd0) + ggtitle("l2fwd overall (MPPS)")
```

### Packet size

```{r fig.width=8, fig.height=6}
ggplot_distribution(l2fwd0) + facet_wrap(~pktsize, ncol=1) + ggtitle("l2fwd by packet size (MPPS)")
```

### Configuration

```{r}
ggplot_distribution(l2fwd0) + facet_wrap(~config, ncol=2, scales = "free_y", shrink = TRUE) + ggtitle("l2fwd by configuration (MPPS)")
```

### DPDK

```{r}
ggplot_distribution(l2fwd0) + facet_wrap(~dpdk, ncol=2, scales = "free_y", shrink = TRUE) + ggtitle("l2fwd by DPDK (MPPS)")
```

### DPDK + configuration

```{r}
ggplot_distribution(l2fwd0) + facet_wrap(dpdk ~ config, scales = "free_y", shrink = TRUE) + ggtitle("l2fwd by DPDK and configuration (MPPS)")
```

### QEMU

```{r}
ggplot_distribution(l2fwd0) + facet_wrap(~qemu, ncol=2, scales = "free_y", shrink = TRUE) + ggtitle("l2fwd by QEMU (MPPS)")
```

### Success and failure

Success rate:

```{r}
success = summarize(group_by(l2fwd, qemu, dpdk, config, snabb), success = mean(!is.na(score)))
ggplot(success, aes(qemu, dpdk, fill=success)) +
  geom_tile(aes(fill=success)) + scale_fill_gradient(limits=c(0,1), low="red", high="white") +
  geom_text(aes(label = scales::percent(success))) +
  facet_grid(snabb ~ config) +
  theme(axis.text.x = element_text(angle=45, vjust=1))
```

Sucesses:

```{r}
summary(subset(l2fwd, subset = !is.na(score), select = c(config, qemu, dpdk, snabb, pktsize)))
```

Failures:

```{r}
summary(subset(l2fwd, subset = is.na(score), select = c(config, qemu, dpdk, snabb, pktsize)))
```
